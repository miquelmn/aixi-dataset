# Assessing fidelity in xai post-hoc techniques: A comparative study with ground truth explanations datasets
### Authors: Miquel Miró-Nicolau, Antoni Jaume-i-Capó, Gabriel Moyà-Alcover

##  Abstract

The evaluation of the fidelity of eXplainable Artificial Intelligence (XAI) methods to their underlying models is a challenging task, primarily due to the absence of a ground truth for explanations. However, assessing fidelity is a necessary step for ensuring a correct XAI methodology. In this study, we conduct a fair and objective comparison of the current state-of-the-art XAI methods by introducing three novel image datasets with reliable ground truth for explanations. The primary objective of this comparison is to identify methods with low fidelity and eliminate them from further research, thereby promoting the development of more trustworthy and effective XAI techniques. Our results demonstrate that XAI methods based on the direct gradient calculation and the backpropagation of output information to input yield higher accuracy and reliability compared to methods relying on perturbation based or Class Activation Maps (CAM). However, these methods tend to generate more noisy saliency maps. These findings have significant implications for the advancement of XAI methods, enabling the elimination of erroneous explanations and fostering the development of more robust and reliable XAI.

## Citation

If you find this dataset or its companion paper
[**Assessing fidelity in XAI post-hoc techniques: A comparative study with ground truth explanations datasets**](https://doi.org/10.1016/j.artint.2024.104179)
interesting or useful in your research, use the following Bibtex annotation to cite us:


```bibtex
@article{miro2024assessing,
  title={Assessing fidelity in xai post-hoc techniques: A comparative study with ground truth explanations datasets},
  author={Mir{\'o}-Nicolau, Miquel and Jaume-i-Cap{\'o}, Antoni and Moy{\`a}-Alcover, Gabriel},
  journal={Artificial Intelligence},
  volume={335},
  pages={104179},
  year={2024},
  publisher={Elsevier}
}
````
